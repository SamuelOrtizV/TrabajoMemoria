{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGAR DEPENDENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from model import CNN_RNN, RacingDataset, CNN_LSTM_STATE\n",
    "import os\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import transforms, models\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINICION DE PARAMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq20TomyBot-CNN_LSTM_STATE-efficientnet_b0-20-240-135-2-256-epoch\n"
     ]
    }
   ],
   "source": [
    "architecture = \"CNN_LSTM_STATE\" # \"CNN_RNN\", \"CNN_LSTM_STATE\"\n",
    "cnn_name = \"efficientnet_b0\"#\"efficientnet_v2_s\", \"efficientnet_b0\", \"efficientnet_b1\", \"efficientnet_b2\", \"efficientnet_b3\"\n",
    "hidden_size = 256 # Número de neuronas en la capa oculta 512 usado por Iker\n",
    "output_size = 2 # Giro y aceleración\n",
    "input_size = (240, 135)  # 16:9 ratio\n",
    "num_layers = 1\n",
    "dropout = 0 # Se necesita num_layers > 1 para que el dropout tenga efecto\n",
    "bias = True\n",
    "cnn_train = True # Si se desea entrenar la parte CNN \n",
    "\n",
    "seq_len = 20 # Número de imágenes a considerar en la secuencia\n",
    "batch_size = 5 # Número de secuencias a considerar en paralelo\n",
    "num_epochs = 30 # Número de veces que se recorrerá el dataset\n",
    "learning_rate = 0.001 \n",
    "\n",
    "# Parámetros del early stopping\n",
    "patience = 5  # Tolerancia de 5 epochs sin mejora\n",
    "best_val_loss = float('inf')  # Inicia con el peor valor posible\n",
    "early_stop_counter = 0  # Contador de epochs sin mejoras\n",
    "\n",
    "\n",
    "# Definir las rutas de los directorios de datos y de guardado de modelos\n",
    "train_data_dir = \"./datasets/train\"\n",
    "validation_data_dir = \"./datasets/validation\"\n",
    "save_dir = \"./trained_models\"\n",
    "\n",
    "model_name = f\"seq20TomyBot-{architecture}-{cnn_name}-{seq_len}-{input_size[0]}-{input_size[1]}-{output_size}-{hidden_size}-epoch\"\n",
    "print(f\"{model_name}\")\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Definir el escritor de TensorBoard para visualización\n",
    "writer = SummaryWriter(log_dir=\"./runs/\" + model_name) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INICIAR MODELO Y CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando CUDA\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo\n",
    "\n",
    "if architecture == \"CNN_RNN\":\n",
    "    model = CNN_RNN(cnn_name, hidden_size, output_size, (3, *input_size), num_layers, dropout, bias)\n",
    "elif architecture == \"CNN_LSTM_STATE\":\n",
    "    model = CNN_LSTM_STATE(cnn_name, hidden_size, output_size, (3, *input_size), num_layers, dropout, bias)\n",
    "    hidden_state = model.init_hidden(batch_size)\n",
    "\n",
    "# Cargar el modelo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Usando CUDA\" if torch.cuda.is_available() else \"USANDO CPU\")\n",
    "\n",
    "\n",
    "# Cargar los datasets\n",
    "train_dataset = RacingDataset(data_dir= train_data_dir, seq_len= seq_len, input_size=input_size, controller = True)\n",
    "test_dataset = RacingDataset(data_dir= validation_data_dir, seq_len= seq_len, input_size=input_size, controller = True)\n",
    "\n",
    "# Crear los dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Optimización y función de pérdida\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#criterion = CrossEntropyLoss(weight=torch.tensor(weights).to(device))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "Trabajando en Epoch 1. Progreso: 100.00%\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected hidden[0] size (1, 4, 256), got [1, 5, 256]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mamp\u001b[38;5;241m.\u001b[39mautocast(device_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16):\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m architecture \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN_LSTM_STATE\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 33\u001b[0m         outputs, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Pasar hidden_state\u001b[39;00m\n\u001b[0;32m     34\u001b[0m         \u001b[38;5;66;03m# Desconectar hidden_state para evitar acumulación de gradientes\u001b[39;00m\n\u001b[0;32m     35\u001b[0m         hidden_state \u001b[38;5;241m=\u001b[39m (hidden_state[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach(), hidden_state[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\PC\\Documents\\GitHub\\TrabajoMemoria\\model.py:207\u001b[0m, in \u001b[0;36mCNN_LSTM_STATE.forward\u001b[1;34m(self, x, hidden_state)\u001b[0m\n\u001b[0;32m    204\u001b[0m conv_out \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(conv_out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Tamaño: (batch_size, seq_len, conv_output_size)\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;66;03m# Pasar la salida de la CNN a la LSTM\u001b[39;00m\n\u001b[1;32m--> 207\u001b[0m lstm_out, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconv_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_state\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# hidden_state incluye (hidden, cell)\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;66;03m# Tomar la última salida de la secuencia y pasarla por la capa fully connected\u001b[39;00m\n\u001b[0;32m    210\u001b[0m final_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(lstm_out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\rnn.py:913\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    910\u001b[0m             hx \u001b[38;5;241m=\u001b[39m (hx[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), hx[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m--> 913\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    914\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\rnn.py:828\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m,  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    823\u001b[0m                        \u001b[38;5;28minput\u001b[39m: Tensor,\n\u001b[0;32m    824\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[0;32m    825\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[0;32m    826\u001b[0m                        ):\n\u001b[0;32m    827\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_input(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m--> 828\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_expected_hidden_size\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m                           \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mExpected hidden[0] size \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, got \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    830\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_cell_size(\u001b[38;5;28minput\u001b[39m, batch_sizes),\n\u001b[0;32m    831\u001b[0m                            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden[1] size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\rnn.py:266\u001b[0m, in \u001b[0;36mRNNBase.check_hidden_size\u001b[1;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_hidden_size\u001b[39m(\u001b[38;5;28mself\u001b[39m, hx: Tensor, expected_hidden_size: Tuple[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mint\u001b[39m],\n\u001b[0;32m    264\u001b[0m                       msg: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected hidden size \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hx\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m expected_hidden_size:\n\u001b[1;32m--> 266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(expected_hidden_size, \u001b[38;5;28mlist\u001b[39m(hx\u001b[38;5;241m.\u001b[39msize())))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected hidden[0] size (1, 4, 256), got [1, 5, 256]"
     ]
    }
   ],
   "source": [
    "print(\"Iniciando entrenamiento...\")\n",
    "\n",
    "start_time = time.time()    # Tiempo de inicio del entrenamiento\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "for epoch in range(num_epochs): \n",
    "\n",
    "    epoch_start_time = time.time()  # Tiempo de inicio del epoch    \n",
    "\n",
    "    # Inicializar el estado oculto (hidden_state) y cell_state\n",
    "    if architecture == \"CNN_LSTM_STATE\":\n",
    "        hidden_state = model.init_hidden(batch_size)  # Estado inicial para LSTM\n",
    "\n",
    "    model.train() # Establecer el modo de entrenamiento\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    try:\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "            print(f\"Trabajando en Epoch {epoch+1}. Progreso: {(i+1)/len(train_loader)*100:.2f}%\", end='\\r')\n",
    "\n",
    "            #print(f\"Dimensiones de las etiquetas en el batch {i+1}: {labels.size()}\")\n",
    "\n",
    "            input_sequence = images # (seq_len, batch_size, channels, height, width)\n",
    "            input_sequence, labels = input_sequence.to(device), labels.to(device) # Mover los datos al dispositivo            \n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Habilitar precisión mixta\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "\n",
    "                if architecture == \"CNN_LSTM_STATE\":\n",
    "                    outputs, hidden_state = model(input_sequence, hidden_state)  # Pasar hidden_state\n",
    "                    # Desconectar hidden_state para evitar acumulación de gradientes\n",
    "                    hidden_state = (hidden_state[0].detach(), hidden_state[1].detach())\n",
    "                elif architecture == \"CNN_RNN\":\n",
    "                    outputs = model(input_sequence)\n",
    "                else:\n",
    "                    print(\"Arquitectura no soportada\")\n",
    "                    break\n",
    "\n",
    "                loss = criterion(outputs, labels) # Solo se considera la última etiqueta de la secuencia\n",
    "            \n",
    "            # Backpropagation y optimización\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        # Registrar la pérdida en TensorBoard\n",
    "        writer.add_scalar('Loss/train', running_loss / len(train_loader), epoch)\n",
    "\n",
    "        # Guardar el modelo después de cada epoch\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, f'{model_name}_{epoch+1}.pth'))\n",
    "\n",
    "        print(\"\\nValidando modelo...\")\n",
    "\n",
    "        # Validación en el conjunto de datos de prueba\n",
    "        model.eval()  # Establecer el modo de evaluación\n",
    "        test_loss = 0.0\n",
    "\n",
    "        # Inicializar el hidden_state para el set de validación\n",
    "        if architecture == \"CNN_LSTM_STATE\":\n",
    "            hidden_state_val = model.init_hidden(batch_size)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (images, labels) in enumerate(validation_loader):\n",
    "                \n",
    "                print(f\"Validando en Epoch {epoch+1}. Progreso: {(i+1)/len(validation_loader)*100:.2f}%\", end='\\r')\n",
    "\n",
    "                input_test_sequence = images # (seq_len, batch_size, channels, height, width)\n",
    "                input_test_sequence, labels = input_test_sequence.to(device), labels.to(device) # Mover los datos al dispositivo\n",
    "\n",
    "                # Actualizar el tamaño del hidden_state_val según el tamaño del lote actual\n",
    "                \n",
    "                if architecture == \"CNN_LSTM_STATE\":\n",
    "                    current_batch_size = input_test_sequence.size(0)\n",
    "                    if hidden_state_val[0].size(1) != current_batch_size:                    \n",
    "                        hidden_state_val = model.init_hidden(current_batch_size)\n",
    "\n",
    "                with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                    if architecture == \"CNN_LSTM_STATE\":\n",
    "                        outputs, hidden_state_val = model(input_test_sequence, hidden_state_val)\n",
    "                        # Desconectar hidden_state_val para evitar acumulación de gradientes\n",
    "                        hidden_state_val = (hidden_state_val[0].detach(), hidden_state_val[1].detach())\n",
    "                    elif architecture == \"CNN_RNN\":\n",
    "                        outputs = model(input_test_sequence)\n",
    "\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    test_loss += loss.item()\n",
    "\n",
    "        val_loss = test_loss / len(validation_loader)\n",
    "        writer.add_scalar('Loss/test', val_loss, epoch)\n",
    "\n",
    "        # Comprobar si early stopping es necesario\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            early_stop_counter = 0  # Restablecer el contador\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f'{model_name}_{epoch+1}.pth'))  # Guardar el mejor modelo\n",
    "        else:\n",
    "            early_stop_counter += 1\n",
    "            if early_stop_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {patience} epochs without improvement.\")\n",
    "                break\n",
    "\n",
    "        end_time = time.time() - start_time  # Tiempo de finalización del epoch\n",
    "        # Convertir end_time a formato hh:mm:ss\n",
    "        end_time = time.strftime(\"%H:%M:%S\", time.gmtime(end_time))\n",
    "        epoch_time = time.time() - epoch_start_time  # Tiempo de finalización del epoch\n",
    "        epoch_time = time.strftime(\"%H:%M:%S\", time.gmtime(epoch_time))\n",
    "        print(f'\\nEpoch [{epoch+1}/{num_epochs}], '\n",
    "            f'Train Loss: {running_loss/len(train_loader):.4f}, '\n",
    "            f'Val Loss: {test_loss/len(validation_loader):.4f}, '\n",
    "            f'Epoch Time: {epoch_time}, '\n",
    "            f'Total Time: {end_time}'\n",
    "            )\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nEntrenamiento interrumpido.\")\n",
    "        break\n",
    "print(\"Entrenamiento terminado.\")\n",
    "\n",
    "writer.close()  # Cerrar el escritor de TensorBoard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
