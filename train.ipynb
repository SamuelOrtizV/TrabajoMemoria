{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CARGAR DEPENDENCIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from model import SimpleRNN, RacingDataset\n",
    "import os\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import transforms, models\n",
    "import time\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINICION DE PARAMETROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pretrained_cnn = models.efficientnet_v2_s(weights='IMAGENET1K_V1') \n",
    "pretrained_cnn = models.efficientnet_b0(weights='IMAGENET1K_V1') \n",
    "hidden_size = 512 # Número de neuronas en la capa oculta 512 usado por Iker\n",
    "output_size = 9 # Número de clases (W, A, S, D, WA, WD, SA, SD, NONE)\n",
    "input_size = (3, 224, 224)  # 16:9 ratio\n",
    "num_layers = 1\n",
    "dropout = 0 # Se necesita num_layers > 1 para que el dropout tenga efecto\n",
    "bias = True\n",
    "\n",
    "seq_len = 5 # Número de imágenes a considerar en la secuencia\n",
    "batch_size = 128 # Número de secuencias a considerar en paralelo\n",
    "num_epochs = 20 # Número de veces que se recorrerá el dataset\n",
    "learning_rate = 0.001 \n",
    "\n",
    "# Definir las rutas de los directorios de datos y de guardado de modelos\n",
    "train_data_dir = \"./datasets/train_dataset\"\n",
    "validation_data_dir = \"./datasets/validation_dataset\"\n",
    "save_dir = \"./trained_models\"\n",
    "\n",
    "model_name = \"Model_EffNet_b0_256_epoch\"\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Definir el escritor de TensorBoard para visualización\n",
    "writer = SummaryWriter(log_dir=\"./runs/exp1\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INICIAR MODELO Y CARGAR DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando CUDA\n"
     ]
    }
   ],
   "source": [
    "# Inicializar el modelo\n",
    "model = SimpleRNN(pretrained_cnn, hidden_size, output_size, input_size, num_layers, dropout, bias)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "print(\"Usando CUDA\" if torch.cuda.is_available() else \"USANDO CPU\")\n",
    "\n",
    "# Definir las transformaciones\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Cambia el tamaño de las imágenes a 72x128 (height x width)\n",
    "    transforms.ToTensor(),         # Convierte las imágenes a tensores\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalizar la imagen\n",
    "])\n",
    "\n",
    "# Cargar los datasets\n",
    "train_dataset = RacingDataset(data_dir= train_data_dir, seq_len= seq_len, transform=transform)\n",
    "test_dataset = RacingDataset(data_dir= validation_data_dir, seq_len= seq_len, transform=transform)\n",
    "\n",
    "# Crear los dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# Optimización y función de pérdida\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENTRENAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando entrenamiento...\n",
      "Trabajando en Epoch 1. Progreso: 100.00%\n",
      "Validando modelo...\n",
      "Validando en Epoch 1. Progreso: 100.00%\n",
      "Epoch [1/20], Train Loss: 1.6785, Test Loss: 1.7434, Accuracy: 41.75% Time: 00:08:13\n",
      "Trabajando en Epoch 2. Progreso: 100.00%\n",
      "Validando modelo...\n",
      "Validando en Epoch 2. Progreso: 100.00%\n",
      "Epoch [2/20], Train Loss: 1.4918, Test Loss: 1.6443, Accuracy: 42.75% Time: 00:16:16\n",
      "Trabajando en Epoch 3. Progreso: 100.00%\n",
      "Validando modelo...\n",
      "Validando en Epoch 3. Progreso: 100.00%\n",
      "Epoch [3/20], Train Loss: 1.3796, Test Loss: 1.8696, Accuracy: 45.25% Time: 00:24:15\n",
      "Trabajando en Epoch 4. Progreso: 100.00%\n",
      "Validando modelo...\n",
      "Validando en Epoch 4. Progreso: 100.00%\n",
      "Epoch [4/20], Train Loss: 1.2937, Test Loss: 2.0946, Accuracy: 44.75% Time: 00:32:15\n",
      "Trabajando en Epoch 5. Progreso: 100.00%\n",
      "Validando modelo...\n",
      "Validando en Epoch 5. Progreso: 100.00%\n",
      "Epoch [5/20], Train Loss: 1.1955, Test Loss: 2.2707, Accuracy: 45.75% Time: 00:40:15\n",
      "Trabajando en Epoch 6. Progreso: 15.35%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     57\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 59\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# Registrar las predicciones para la matriz de confusión\u001b[39;00m\n\u001b[0;32m     62\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Iniciando entrenamiento...\")\n",
    "\n",
    "start_time = time.time()    # Tiempo de inicio del entrenamiento\n",
    "\n",
    "# Ciclo de entrenamiento\n",
    "for epoch in range(num_epochs): \n",
    "    \n",
    "    # Iniciar buffer de secuencia\n",
    "    sequence_buffer_train = []\n",
    "    sequence_buffer_validation = []\n",
    "\n",
    "    predictions_list = [] \n",
    "    labels_list = [] \n",
    "    T_o_F_list = []\n",
    "    \n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        print(f\"Trabajando en Epoch {epoch+1}. Progreso: {(i+1)/len(train_loader)*100:.2f}%\", end='\\r')\n",
    "\n",
    "        \"\"\" print(labels)\n",
    "        break \"\"\"\n",
    "        \"\"\" if labels == 3: # Balanceo express para el exceso de W\n",
    "            if random.random() < 0.6:\n",
    "                continue  \"\"\"   \n",
    "\n",
    "        \"\"\" # Añadir la secuencia al buffer\n",
    "        if len(sequence_buffer_train) < seq_len: # Si el buffer no está lleno aún, se añade la imagen al buffer y se continúa con la siguiente iteración\n",
    "            sequence_buffer_train.append(images)\n",
    "            continue\n",
    "\n",
    "        # Eliminar la imagen más antigua del buffer\n",
    "        sequence_buffer_train.pop(0)\n",
    "        sequence_buffer_train.append(images) \"\"\"        \n",
    "\n",
    "        input_sequence = images # (seq_len, batch_size, channels, height, width)\n",
    "\n",
    "        #get images size\n",
    "        #print(input_sequence.size())\n",
    "\n",
    "        # Cambiar la forma de input_sequence para que el batch size sea ??\n",
    "        #input_sequence = input_sequence.permute(1,0, 2, 3, 4) # (batch_size, seq_len, channels, height, width) NO SE SI ESTA PARTE SE CAMBIA SI SE AUMENTA EL BATCH SIZE\n",
    "        \n",
    "        input_sequence, labels = input_sequence.to(device), labels.to(device) # Mover los datos al dispositivo\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Habilitar precisión mixta\n",
    "        with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "            outputs = model(input_sequence)\n",
    "            loss = criterion(outputs, labels) # Solo se considera la última etiqueta de la secuencia\n",
    "        \n",
    "        # Backpropagation y optimización\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Registrar las predicciones para la matriz de confusión\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions_list.append(predicted.cpu().numpy())\n",
    "        labels_list.append(labels.cpu().numpy())\n",
    "        T_o_F_list.append(labels.cpu().numpy() == predicted.cpu().numpy())\n",
    "    \n",
    "    # Guardar las predicciones en un archivo CSV\n",
    "    predictions_df = pd.DataFrame({\n",
    "    'Labels': labels_list,\n",
    "    'Predictions': predictions_list,\n",
    "    'T o F': T_o_F_list\n",
    "    })\n",
    "\n",
    "    predictions_df.to_csv(f'predictions_{model_name}_{epoch+1}.csv', index=False)\n",
    "\n",
    "    # Registrar la pérdida en TensorBoard\n",
    "    writer.add_scalar('Loss/train', running_loss / len(train_loader), epoch)\n",
    "\n",
    "    # Guardar el modelo después de cada epoch\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f'{model_name}_{epoch+1}.pth'))\n",
    "\n",
    "    print(\"\\nValidando modelo...\")\n",
    "\n",
    "\n",
    "    # Validación en el conjunto de datos de prueba\n",
    "    model.eval()  # Establecer el modo de evaluación\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(validation_loader):\n",
    "            \n",
    "            print(f\"Validando en Epoch {epoch+1}. Progreso: {(i+1)/len(validation_loader)*100:.2f}%\", end='\\r')\n",
    "            \n",
    "            \"\"\"  # Añadir la secuencia al buffer\n",
    "            if len(sequence_buffer_validation) < seq_len:\n",
    "                sequence_buffer_validation.append(images_seq)\n",
    "                continue\n",
    "\n",
    "            # Eliminar la imagen más antigua del buffer\n",
    "            sequence_buffer_validation.pop(0)\n",
    "            sequence_buffer_validation.append(images) \"\"\"\n",
    "\n",
    "            # Apilar las imágenes en una sola dimensión\n",
    "            input_test_sequence = images # (seq_len, batch_size, channels, height, width)\n",
    "\n",
    "            # Cambiar la forma de input_sequence para que el batch size sea ??\n",
    "            #input_test_sequence = input_test_sequence.permute(1,0, 2, 3, 4) # (batch_size, seq_len, channels, height, width)\n",
    "\n",
    "            input_test_sequence, labels = input_test_sequence.to(device), labels.to(device) # Mover los datos al dispositivo\n",
    "\n",
    "            with torch.amp.autocast(device_type='cuda', dtype=torch.float16):\n",
    "                outputs = model(input_test_sequence)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Predicción y cálculo de precisión\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    writer.add_scalar('Loss/test', test_loss / len(validation_loader), epoch)\n",
    "    writer.add_scalar('Accuracy/test', accuracy, epoch)\n",
    "\n",
    "    end_time = time.time() - start_time  # Tiempo de finalización del epoch\n",
    "    # Convertir end_time a formato hh:mm:ss\n",
    "    end_time = time.strftime(\"%H:%M:%S\", time.gmtime(end_time))\n",
    "\n",
    "    print(f'\\nEpoch [{epoch+1}/{num_epochs}], '\n",
    "          f'Train Loss: {running_loss/len(train_loader):.4f}, '\n",
    "          f'Test Loss: {test_loss/len(validation_loader):.4f}, '\n",
    "          f'Accuracy: {accuracy:.2f}% '\n",
    "          f'Time: {end_time}')\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n",
    "\n",
    "writer.close()  # Cerrar el escritor de TensorBoard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
